{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc6d15d",
   "metadata": {},
   "source": [
    "\n",
    "Q1. What is data encoding? How is it useful in data science?\n",
    "\n",
    "Data encoding is the process of converting data from one format or representation to another, such as converting text to binary code or encoding images in a specific file format. The purpose of data encoding is to make it easier to transmit, store, or process data.\n",
    "\n",
    "In data science, data encoding is important because it helps to prepare data for analysis. For example, in natural language processing, text data must be encoded into a numerical representation, such as word embeddings, before it can be used in machine learning models. Similarly, in computer vision, images must be encoded in a specific format, such as JPEG or PNG, to be processed by machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03952ece",
   "metadata": {},
   "source": [
    "Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n",
    "\n",
    "Nominal encoding, also known as one-hot encoding, is a technique used in data science to transform categorical variables into numerical variables that can be used in machine learning models. In nominal encoding, each category is assigned a unique integer value, and then transformed into a binary vector where only one value is \"on\" or \"hot\" for each category.\n",
    "\n",
    "For example, let's say we have a dataset of customer reviews for a restaurant, and one of the variables is \"cuisine type\", which includes categories such as \"Italian\", \"Mexican\", and \"Chinese\". To use this variable in a machine learning model, we could use nominal encoding to convert it into a binary vector with a 1 for the category that applies to each row, and 0s for all other categories. So, for a row with \"Italian\" cuisine type, the vector would be [1, 0, 0], while for a row with \"Mexican\" cuisine type, the vector would be [0, 1, 0].\n",
    "\n",
    "Nominal encoding is useful in a variety of real-world scenarios, particularly in the field of natural language processing. For example, in sentiment analysis, we may have a dataset of customer reviews for a product or service, where one of the variables is \"sentiment\", with categories such as \"positive\", \"negative\", and \"neutral\". By using nominal encoding to transform this variable into a binary vector, we can feed it into a machine learning algorithm to predict the sentiment of new reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65680767",
   "metadata": {},
   "source": [
    "Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    "\n",
    "Nominal encoding and one-hot encoding are actually the same thing, with \"nominal encoding\" being another term for \"one-hot encoding\". So, there are no situations where nominal encoding is preferred over one-hot encoding, as they refer to the same technique.\n",
    "\n",
    "One-hot encoding is preferred over other encoding techniques for categorical variables, such as ordinal encoding, because it does not impose any ordinal relationship between the categories. This means that each category is treated as a separate entity, and the machine learning algorithm does not assume any relationship or order between the categories.\n",
    "\n",
    "For example, let's say we have a variable called \"education level\", with categories such as \"high school\", \"college\", and \"graduate school\". If we use ordinal encoding to transform this variable into numerical values, we might assign \"high school\" a value of 1, \"college\" a value of 2, and \"graduate school\" a value of 3. This implies an order or hierarchy between the categories, which may not be accurate or relevant to the problem at hand. One-hot encoding avoids this issue by transforming each category into a separate binary vector, without assuming any relationship between the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe66dd63",
   "metadata": {},
   "source": [
    "Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding\n",
    "technique would you use to transform this data into a format suitable for machine learning algorithms?\n",
    "Explain why you made this choice.\n",
    "\n",
    "If we have a dataset containing categorical data with 5 unique values, we would use one-hot encoding to transform this data into a format suitable for machine learning algorithms. One-hot encoding is a technique that transforms categorical variables into numerical variables by creating a binary vector for each category, where one value is \"on\" or \"hot\" for each category, and all other values are \"off\" or \"not hot\".\n",
    "\n",
    "One-hot encoding is the preferred encoding technique for categorical variables in most situations, as it avoids imposing any order or hierarchy between the categories. This means that each category is treated as a separate entity, and the machine learning algorithm does not assume any relationship or order between the categories.\n",
    "\n",
    "For example, let's say we have a categorical variable called \"fruit type\", with 5 unique values: \"apple\", \"banana\", \"orange\", \"mango\", and \"pineapple\". To use this variable in a machine learning model, we could use one-hot encoding to create a binary vector for each category, where one value is \"on\" or \"hot\" for the corresponding category, and all other values are \"off\" or \"not hot\". The resulting encoded dataset would contain one binary vector for each row, with 5 elements, one for each unique value of the original \"fruit type\" variable.\n",
    "\n",
    "In summary, when we have a dataset containing categorical data with 5 unique values, we would use one-hot encoding to transform this data into a format suitable for machine learning algorithms, as it avoids imposing any order or hierarchy between the categories and treats each category as a separate entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced364c",
   "metadata": {},
   "source": [
    "Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\n",
    "are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to\n",
    "transform the categorical data, how many new columns would be created? Show your calculations.\n",
    "\n",
    "If we were to use nominal encoding to transform the categorical data in a dataset with 1000 rows and 5 columns, and two of the columns are categorical, we would create new columns equal to the number of unique categories in those columns. Each categorical column would be transformed into a binary vector, with a 1 in the column corresponding to the category for that row, and 0s in all other columns.\n",
    "\n",
    "To calculate the number of new columns created by nominal encoding, we need to first calculate the number of unique categories in each categorical column. Let's assume that the first categorical column has 4 unique categories, and the second categorical column has 3 unique categories.\n",
    "\n",
    "For the first categorical column, we would create 4 new columns, one for each unique category. For the second categorical column, we would create 3 new columns, one for each unique category.\n",
    "\n",
    "So, in total, nominal encoding would create 7 new columns in this dataset: 4 for the first categorical column and 3 for the second categorical column. The remaining three numerical columns would not be affected by the encoding process.\n",
    "\n",
    "Therefore, the final dataset after nominal encoding would have 1000 rows and 10 columns (5 original columns + 4 new columns from the first categorical column + 3 new columns from the second categorical column)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b6c0f",
   "metadata": {},
   "source": [
    "Q6. You are working with a dataset containing information about different types of animals, including their\n",
    "species, habitat, and diet. Which encoding technique would you use to transform the categorical data into\n",
    "a format suitable for machine learning algorithms? Justify your answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9d41cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'animal_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25184\\963271413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load animal dataset from CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'animal_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Perform one-hot encoding on the \"species\" column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'animal_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load animal dataset from CSV file\n",
    "df = pd.read_csv('animal_data.csv')\n",
    "\n",
    "# Perform one-hot encoding on the \"species\" column\n",
    "species_encoded = pd.get_dummies(df['species'], prefix='species')\n",
    "\n",
    "# Replace original \"species\" column with encoded columns\n",
    "df = pd.concat([df.drop('species', axis=1), species_encoded], axis=1)\n",
    "\n",
    "# Print first 5 rows of encoded dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05df7be",
   "metadata": {},
   "source": [
    "In this example code, we first load the animal dataset from a CSV file using the pandas read_csv() function. We then perform one-hot encoding on the \"species\" column using the get_dummies() function from pandas, which creates a binary vector for each unique value in the column. We prefix the name of the new columns with \"species_\" using the prefix argument to get_dummies().\n",
    "\n",
    "Finally, we replace the original \"species\" column with the new encoded columns using the concat() function from pandas, which concatenates the original dataset with the encoded columns along the columns axis (axis=1). We drop the original \"species\" column using the drop() function from pandas, which removes the column from the dataset.\n",
    "\n",
    "We can then print the first 5 rows of the encoded dataset using the head() function from pandas, which displays the first n rows of the dataset (n=5 by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9c52a",
   "metadata": {},
   "source": [
    "Q7.You are working on a project that involves predicting customer churn for a telecommunications\n",
    "company. You have a dataset with 5 features, including the customer's gender, age, contract type,\n",
    "monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical\n",
    "data into numerical data? Provide a step-by-step explanation of how you would implement the encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2c992",
   "metadata": {},
   "source": [
    "To transform the categorical data in the customer churn dataset into numerical data, we can use a combination of nominal encoding and one-hot encoding.\n",
    "\n",
    "Here is a step-by-step explanation of how we can implement the encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('customer_churn.csv')\n",
    "categorical_features = ['contract_type']\n",
    "df['contract_type'] = df['contract_type'].replace({'month-to-month': 1, 'one_year': 2, 'two_year': 3})\n",
    "df = pd.get_dummies(df, columns=['gender'])\n",
    "numerical_features = ['age', 'monthly_charges', 'tenure']\n",
    "X = pd.concat([df[categorical_features], df[numerical_features]], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c6d97",
   "metadata": {},
   "source": [
    "The resulting DataFrame X will contain the encoded categorical features and the numerical features, which can then be used for machine learning algorithms.\n",
    "In this example, we first load the customer churn dataset into a pandas DataFrame using the read_csv() function. We then identify the categorical feature, \"contract type\", and apply nominal encoding using the replace() function from pandas.\n",
    "\n",
    "We then apply one-hot encoding to the remaining categorical feature, \"gender\", using the get_dummies() function from pandas. We specify the \"gender\" column using the columns argument to get_dummies().\n",
    "\n",
    "We then combine the encoded categorical features with the numerical features in the dataset using the pandas concat() function, which concatenates the DataFrames along the columns axis (axis=1). We specify the categorical features and numerical features separately using the categorical_features and numerical_features variables.\n",
    "\n",
    "Finally, the resulting DataFrame X contains the encoded categorical features and the numerical features, which can then be used for machine learning algorithms to predict customer churn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
